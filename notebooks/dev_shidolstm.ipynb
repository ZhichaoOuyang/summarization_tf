{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NstepRNN`系はcudnnを使っているため中断すると確実にカーネルが落ちる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "from matplotlib import pylab as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from layers import *\n",
    "from utils import *\n",
    "from models import *\n",
    "import json\n",
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager \n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"1\"))\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "tf.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_data = read_pickle(\"../dataset/nl/train.pkl\")\n",
    "vld_data = read_pickle(\"../dataset/nl/valid.pkl\")\n",
    "tst_data = read_pickle(\"../dataset/nl/test.pkl\")\n",
    "code_i2w = read_pickle(\"../dataset/code_i2w.pkl\")\n",
    "code_w2i = read_pickle(\"../dataset/code_w2i.pkl\")\n",
    "nl_i2w = read_pickle(\"../dataset/nl_i2w.pkl\")\n",
    "nl_w2i = read_pickle(\"../dataset/nl_w2i.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_x, trn_y_raw = zip(*trn_data.items())\n",
    "vld_x, vld_y_raw = zip(*vld_data.items())\n",
    "tst_x, tst_y_raw = zip(*tst_data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_y = [[nl_w2i[t] if t in nl_w2i.keys() else nl_w2i[\"<UNK>\"] for t in l] for l in trn_y_raw]\n",
    "vld_y = [[nl_w2i[t] if t in nl_w2i.keys() else nl_w2i[\"<UNK>\"] for t in l] for l in vld_y_raw]\n",
    "tst_y = [[nl_w2i[t] if t in nl_w2i.keys() else nl_w2i[\"<UNK>\"] for t in l] for l in tst_y_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model\n",
    "# model = Model(512, 512, 512, len(code_w2i), len(nl_w2i))\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "# checkpoint_dir = \"/mnt/hdd/models/summarize/childsum_alldata_1layer\"\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# root = tfe.Checkpoint(model=model)\n",
    "history = {\"loss\":[], \"loss_val\":[], \"bleu\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting Data Generator\n",
    "\n",
    "trn_gen = Datagen_tree(trn_x, trn_y, batch_size, code_w2i, nl_i2w, train=True)\n",
    "vld_gen = Datagen_tree(vld_x, vld_y, batch_size, code_w2i, nl_i2w, train=False)\n",
    "tst_gen = Datagen_tree(tst_x, tst_y, batch_size, code_w2i, nl_i2w, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = trn_gen(0)\n",
    "for x, y, _, _ in gen:\n",
    "    x, y, _, _ = x, y, _, _\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=705, shape=(64, 31), dtype=int32, numpy=\n",
       "array([[ 1377,  6563, 24460, ...,    -1,    -1,    -1],\n",
       "       [ 1377,  4642, 21914, ...,    -1,    -1,    -1],\n",
       "       [ 1377,  9943, 13533, ...,    -1,    -1,    -1],\n",
       "       ...,\n",
       "       [ 1377, 11351, 20333, ...,    -1,    -1,    -1],\n",
       "       [ 1377,  6563, 28079, ...,    -1,    -1,    -1],\n",
       "       [ 1377,  5355, 28045, ...,    -1,    -1,    -1]], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BiLSTM(tf.keras.Model):\n",
    "    def __init__(self, dim):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.LSTM_f = tf.keras.layers.CuDNNLSTM()\n",
    "\n",
    "class ShidoTreeLSTM(tf.keras.Model):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ShidoTreeLSTM, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        self.U_f = tf.keras.layers.Dense(dim_out, use_bias=False)\n",
    "        self.U_iuo = tf.keras.layers.Dense(dim_out * 3, use_bias=False)\n",
    "        self.W = tf.keras.layers.Dense(dim_out * 4, use_bias=False)\n",
    "        self.h_init = tfe.Variable(\n",
    "            tf.get_variable(\"h_init\", [1, dim_out], tf.float32, initializer=he_normal()))\n",
    "        self.c_init = tf.constant(0., tf.float32, [1, self.dim_out])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_nums(roots):\n",
    "        res = [[x.num for x in n.children] if n.children != [] else [0] for n in roots]\n",
    "        max_len = max([len(x) for x in res])\n",
    "        res = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            res, max_len, padding=\"post\", value=-1.)\n",
    "        return tf.constant(res, tf.int32)\n",
    "\n",
    "    def call(self, roots):\n",
    "        depthes = [x[1] for x in sorted(depth_split_batch2(\n",
    "            roots).items(), key=lambda x:-x[0])]  # list of list of Nodes\n",
    "        indices = [self.get_nums(nodes) for nodes in depthes]\n",
    "\n",
    "        h_tensor = self.h_init\n",
    "        c_tensor = self.c_init\n",
    "        for indice, nodes in zip(indices, depthes):\n",
    "            x = tf.stack([node.h for node in nodes])  # [nodes, dim_in]\n",
    "            h_tensor, c_tensor = self.apply(x, h_tensor, c_tensor, indice, nodes)\n",
    "            h_tensor = tf.concat([self.h_init, h_tensor], 0)\n",
    "            c_tensor = tf.concat([self.c_init, c_tensor], 0)\n",
    "        return depthes[-1]\n",
    "\n",
    "    def apply(self, x, h_tensor, c_tensor, indice, nodes):\n",
    "\n",
    "        mask_bool = tf.not_equal(indice, -1.)\n",
    "        mask = tf.cast(mask_bool, tf.float32)  # [batch, child]\n",
    "\n",
    "        h = tf.gather(h_tensor, tf.where(mask_bool,\n",
    "                                         indice, tf.zeros_like(indice)))  # [nodes, child, dim]\n",
    "        c = tf.gather(c_tensor, tf.where(mask_bool,\n",
    "                                         indice, tf.zeros_like(indice)))\n",
    "        h_sum = tf.reduce_sum(h * tf.expand_dims(mask, -1), 1)  # [nodes, dim_out]\n",
    "\n",
    "        W_x = self.W(x)  # [nodes, dim_out * 4]\n",
    "        W_f_x = W_x[:, :self.dim_out * 1]  # [nodes, dim_out]\n",
    "        W_i_x = W_x[:, self.dim_out * 1:self.dim_out * 2]\n",
    "        W_u_x = W_x[:, self.dim_out * 2:self.dim_out * 3]\n",
    "        W_o_x = W_x[:, self.dim_out * 3:]\n",
    "\n",
    "        branch_f_k = tf.reshape(self.U_f(tf.reshape(h, [-1, h.shape[-1]])), h.shape)\n",
    "        branch_f_k = tf.sigmoid(tf.expand_dims(W_f_x, 1) + branch_f_k)\n",
    "        branch_f = tf.reduce_sum(branch_f_k * c * tf.expand_dims(mask, -1), 1)  # [node, dim_out]\n",
    "\n",
    "        branch_iuo = self.U_iuo(h_sum)  # [nodes, dim_out * 3]\n",
    "        branch_i = tf.sigmoid(branch_iuo[:, :self.dim_out * 1] + W_i_x)   # [nodes, dim_out]\n",
    "        branch_u = tf.tanh(branch_iuo[:, self.dim_out * 1:self.dim_out * 2] + W_u_x)\n",
    "        branch_o = tf.sigmoid(branch_iuo[:, self.dim_out * 2:] + W_o_x)\n",
    "\n",
    "        new_c = branch_i * branch_u + branch_f  # [node, dim_out]\n",
    "        new_h = branch_o * tf.tanh(new_c)  # [node, dim_out]\n",
    "\n",
    "        for n, c, h in zip(nodes, new_c, new_h):\n",
    "            n.c = c\n",
    "            n.h = h\n",
    "\n",
    "        return new_h, new_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:001, loss = 6.775298118591309:   1%|          | 28/2382 [00:42<1:01:59,  1.58s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-edb19645ea3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:{:03d}, loss = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-773cef4dd84b>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shido/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[1;32m    856\u001b[0m     flat_grad = imperative_grad.imperative_grad(\n\u001b[1;32m    857\u001b[0m         \u001b[0m_default_vspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         output_gradients=output_gradients)\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shido/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(vspace, tape, target, sources, output_gradients)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \"\"\"\n\u001b[1;32m     62\u001b[0m   return pywrap_tensorflow.TFE_Py_TapeGradient(\n\u001b[0;32m---> 63\u001b[0;31m       tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[0;32m/home/shido/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shido/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BiasAddGrad\u001b[0;34m(op, received_grad)\u001b[0m\n\u001b[1;32m    293\u001b[0m   return (received_grad,\n\u001b[1;32m    294\u001b[0m           gen_nn_ops.bias_add_grad(\n\u001b[0;32m--> 295\u001b[0;31m               out_backprop=received_grad, data_format=data_format))\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shido/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add_grad\u001b[0;34m(out_backprop, data_format, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BiasAddGrad\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         data_format)\n\u001b[0m\u001b[1;32m    780\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # train\n",
    "    loss_tmp = []\n",
    "    t = tqdm(trn_gen(epoch))\n",
    "    for x, y, _, _ in t:\n",
    "        loss_tmp.append(model.train_on_batch(x, y))\n",
    "        t.set_description(\"epoch:{:03d}, loss = {}\".format(epoch + 1, np.mean(loss_tmp)))\n",
    "    history[\"loss\"].append(np.sum(loss_tmp) / len(t))\n",
    "    \n",
    "    loss_tmp = []\n",
    "    t = tqdm(vld_gen(epoch))\n",
    "    for x, y, _, _ in t:\n",
    "        loss_tmp.append(model.evaluate_on_batch(x, y))\n",
    "        t.set_description(\"epoch:{:03d}, loss_val = {}\".format(epoch + 1, np.mean(loss_tmp)))\n",
    "    history[\"loss_val\"].append(np.sum(loss_tmp) / len(t))\n",
    "    \n",
    "    # checkpoint\n",
    "    if history[\"loss_val\"][-1] == min(history[\"loss_val\"]):\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "        root.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "    # print\n",
    "    clear_output()\n",
    "    for key, val in history.items():\n",
    "        if \"loss\" in key:\n",
    "            plt.plot(val, label=key)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "with open(os.path.join(checkpoint_dir, \"history.json\"), \"w\") as f:\n",
    "    json.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "trues = []\n",
    "for x, y, _, y_raw in tqdm(tst_gen(0)):\n",
    "    res = model.translate(x, nl_i2w, nl_w2i)\n",
    "    preds += res\n",
    "    trues += [s[1:-1] for s in y_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def ngram(words, n):\n",
    "    return list(zip(*(words[i:] for i in range(n))))\n",
    "\n",
    "def bleu4(true, pred):\n",
    "    c = len(pred)\n",
    "    r = len(true)\n",
    "    bp = 1. if c > r else np.exp(1 - r / c)\n",
    "    score = 0\n",
    "    for i in range(1, 5):\n",
    "        true_ngram = set(ngram(true, i))\n",
    "        pred_ngram = ngram(pred, i)\n",
    "        length = float(len(pred_ngram)) + 1e-10\n",
    "        count = sum([1. if t in true_ngram else 0. for t in pred_ngram])\n",
    "        score += math.log(1e-10 + (count / length))\n",
    "    score = math.exp(score * .25)\n",
    "    bleu = bp * score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bleus = Parallel(n_jobs=-1)(delayed(bleu4)(t, p) for t, p in tqdm(list(zip(trues, preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bleus)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "001018f422af423eb11112050fdfaecc": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "00871cdb23694e418eacc74132df2408": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "0336ae3580b24f3c80e054784c568d7b": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "04efaf290f384b1dbc7ba54e9ff8dbfa": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "0d2b6f2803df4eac8d30aee2156016f8": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "0e944bbb93b042c1939b120835f61fae": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "0f38a0a810a148c5b21b1ccf90f9e894": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "11b4ec3c556b4ffda4cf3eeb9f56ae23": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "12364a43d57a4520bb1b2f02adb0eb10": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "1416e69255344ad2828663a893071f64": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "150981e273474b3185a1cdf23addfc67": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "15a5f5e733d84c988e995ab2f8111a8d": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "16873cb28428445daa978d1b0837f7b2": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "16ff51826190480288c4dbf58e05c768": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "1b63e9f2b15a4b35aadf257c8d962300": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "1cc7f45428a14dba9229b1b8e2540833": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "1fcbfaa5e471411d9f44259c515ada5e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2074134961ce4ec7883f2a5387f9aef0": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "22fe119ddbcd4991a042ee38aeb4d8a3": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2732840d0a2e4861bc249f38e85a91d7": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "28639fc950524e279b4a6e2369c0a0ae": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2a7f7fd1788b4a20b6d27e0d38f59d30": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2df1a01eac7e4a7faf8b29e3a98764af": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2e0eab565288475690e09d29fea8fbe8": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "306e11a98b0b4037bccc20c141439029": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "355e666921ac44789b10daa9db9e10e4": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3748eec32da4443698f6a6eaf77a7e58": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "37e0f6fb8baa44fcb9da8744e9e2b3d4": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "383e9a475bae4083ab53c2a1ec0d7f96": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "38b997170b034f4f80dcd6bd23540493": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "39e542dba23b4057a20b76063844900d": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3a723f3ba8a947dab4a8832e8f324d97": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3a9c0938948d4d06a49bde9fcc8325d0": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3ac990ac3f554e119b51358967d21ce3": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3b59128c278b467e86fefe5d55194a97": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3d67d4852b03459385f80b05ed29def0": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3e6d6a59540d4e65be92b77df7a95026": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3e95c914f88842fb85b4607e042fc2d0": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "3fb244cc3fdd402fb933ded04d459d24": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "4032d55ab6304a09a8b5b2ed63deac74": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "41e76708288a477690db013e6db89778": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "42af2cd3c5f14e0a840ce686f7b84edc": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "44331f96dda748048a20641106ad9c59": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "48a6ae1b192c4e809c428220a76501c5": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "4e2868ae7c8149ad802b517b120dec13": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "4ff422cf37b040f992e8a528d2c4885b": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "51dc9e14d6634a4e96a5ad59e4455f4c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "54598a1869eb49dfb05a626753807877": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "54f5b6411679454f9ef77c042ba732f3": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "58be7ef5c68e4e7f988b382acd152bef": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "5a2d1c4cdfff48b188e70ecbf3740d41": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "5ec9a4fa5f7442d29c1d2932aa823db9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "5fb9aaefa4144b9b97e49818a127fd80": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "60cb36a36910427c86bff25c30a15f9c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "641fbcbb3f43479c8a491faca4711add": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "64e01e5c062542859c716b8efbc1782e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "65c4c73b841f457c85491ef2463e1071": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "679528ad8e1d466b843fc570843e2ec3": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6b3b7c57d2cb4bab9b05be19bdde2757": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6b6f98c0902f43c09a59f920e8ad2c94": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6e286095fe654f2b84084e373b10d616": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6ee06998a35647b495fe90a4cc884e7c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "70bce6473d0740339a76767246d82d39": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "736e5f54649840049c179ff0b44222d9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "76a2ef0ab8ab4432ac1e735e21cd30b0": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "77ab30c2879b47239f1078dd64f889f2": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "7b74cff6f72545fb90291d3a1841b76d": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "7be7972b00f74bd88e80d903e2159dbf": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "7d8d323ebaa14ffaa9293d55c13a86c9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "7f76e4ddfbb0411d918347558f1768bd": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8401dcd2e50a486d8a844c6d434a9e7f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "88871f6da9f8492c88ecb4cb628e6a82": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "89576bfbf3a942e6bbf15455495aab3b": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "89a19b6f3c4140668e9f002512015415": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8ea273f6fee64305afb6beffa3764178": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8ecfc7fb4f984fb78a04d5696cfa0624": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8efe86853c3742819d40e6de97b53afb": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "950b69d325df4ddb86c628ac3974dbb6": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "9c771c6187d34120b2ef9e68ba05b9af": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "9d8af7e414f445008bb261843bbfaf09": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "a028861d725a48a1983693c9cf724b5c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "a6bfc3acf69642b2a92c0a8433aca2b8": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "a785fb597b354262a1fef188ebb67f0c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "add945fb156a4498a550718e45bf717e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "af7faab4d8b24a0098afab7b69dbdc8c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "b11f7aadfd7544149c35c88a07800917": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "b126ffb928644850a8660424dc89835c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "b16e2e3a73ea421ca93662d175cb1f0c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "b192ec4e41064afa8f402e3416568b74": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "b250932b10b8437787db44fec995f859": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "b6c78a30b6e548f9a0df8ab41017c90f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "b7b27596a141466fb66afa7dd53bdff9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "bb52a722153a49cdacf62665eb766b6f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "bc099494e0b4426184d159d2f6a214f9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "bc98446757a74217b87877ef42b4dc0c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "bd72a94ac175418d91e50ec205f24862": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "be761ad00f6849c9a9dfc7930bcd9055": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "bf6ecd912a1b4c4aa50b00f008d75f2b": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c0542351c2e84d63b850c65eeae173f3": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c0b4a772bce8495bb18eb24274d700cc": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c18e7da043714f3d9e01e658cd78a2b2": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c503f3a6420c4d77a94cfc8ae4c52fb1": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c9a315159c3f4346b98c90bce73a0de0": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c9f6b8f53d214a359ac31def8b5ea745": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ca259ce70da54a3ca3cd41f2573e267e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ca40a66733214ef2925d9a8bbead8539": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "cb3f8052e432461196e6a95db3e86bc0": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "cca6fa54cea74154ac0c9c884b0ff5e2": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ced5f66679b0419d837feae5a5c3414d": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "cfa1229d3bac4bbfb57eb022fc87aaa7": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d0b85991b9214d75b476df82448fa414": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d85bb7315f9c4cc183ca94eeddd5d508": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d8e741ee2bee47cc9d13b3bc10091c4f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d90586277b0740fa91034ddfb319c42d": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d94f04e0390644fcbd52ecb09d8147f8": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "dc29ab306e2043f4b53f82e0c005a604": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "dcf3e3b22eab4e7a82d6e4b4f945d793": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "df04e47b6e514f53af73cc4b56c9e143": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "e213b42d10fc471a9ee7d1c0b123e038": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "e2334565d32c455dad2e5a1404b690cd": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "e3844b0e1c5b42ff8da18c599ba17de2": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "e79ffe70202f47db8381ebd00cb23262": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ec3fc10dc26d47c3a5f2d40f4bf99f13": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ed222043074b4024844f85caf207304f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ed4e69d2c1a94ba7b4d465d0743c4c10": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "edde7739c58d45c18196fe03ce9b247f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ee339c27f0424dbd98777a76ff51ccf2": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "f0ff0dcffa094631bd0bb1128260bd6d": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "f4358c6a34fa420db119dc894d0bd564": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "f82e5b2df5b443aeadc17c566ba14fb3": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "f905dec177fb494ca755038339789a6d": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "f94a703f8363496ea27e5913a3c9eb41": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "fbe0ce05166c41b8a36373f099d592c9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "ffb22a3dfaf8403d838ad496a5058cdb": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
